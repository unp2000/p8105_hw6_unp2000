---
title: "p8105_hw6_unp2000"
author: Uma Palaniappan 
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse) 
library(modelr)
```
# Problem 1: 

```{r}
child_data = read_csv("./data/birthweight.csv") %>%
janitor::clean_names () %>%
  mutate( 
      babysex = factor(babysex, levels = c(1,2), labels = c("male", "female")), 
      frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), labels = c("white", "black", "asian", "puerto rican", "other", "unknown")),
      mrace = factor(mrace, levels = c(1, 2, 3, 4, 8, 9), labels = c("white", "black", "asian", "puerto rican", "other", "unknown")),
      malform = factor(malform, levels = c(0,1), labels = c("absent", "present"))
      )
```

# Regression Model 

## Creating Initial Regression Model: 

Variables were selected based on a literature search of predictors of low birthweight. Based on this, babysex, gaweeks, momage, mheight, parity, ppbmi, pnumlbw, and smoken were selected as variables to include in the model. 

```{r}
bw_model1 = lm(bwt ~ babysex + gaweeks + momage + mheight + parity + ppbmi + pnumlbw + smoken, data = child_data)

bw_model1
```

Plotting residuals against fitted values: 

```{r}
plot_1 = child_data %>%
  modelr::add_residuals(bw_model1) %>%
  modelr::add_predictions(bw_model1) %>%
  ggplot(aes(x = pred, y = resid)) + geom_point (color = "blue") 

plot_1
```

## Comparing Models 

Model 2: Length at Birth (blength) and Gestational Age (gaweeks)
```{r}
bw_model2 = lm(bwt ~ blength + gaweeks, data = child_data)

bw_model2
```

Model 3: Head Circumference (bhead), Length at Birth (blength), Sex (babysex)
```{r}
bw_model3 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = child_data)

bw_model3 
```

Cross Validation and Prediction 
```{r, warning = FALSE}
cv_bwt = crossv_mc(child_data, 100)

cv_bwt = 
  cv_bwt %>%
  mutate(bw_model1 = map(train, ~lm(bwt ~ babysex + gaweeks + momage + mheight + parity
                                    + ppbmi + pnumlbw + smoken, data = .x)),
         bw_model2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         bw_model3 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))
  ) %>%
  mutate(rmse_model1 = map2_dbl(bw_model1, test, ~rmse(model = .x, data = .y)),
         rmse_model2 = map2_dbl(bw_model2, test, ~rmse(model = .x, data = .y)),
         rmse_model3 = map2_dbl(bw_model3, test, ~rmse(model = .x,  data = .y))
  )

cv_bwt %>%
  select(starts_with("rmse")) %>%
  pivot_longer (
    everything (),
    names_to = "model", 
    values_to = "rmse", 
    names_prefix = "rmse_") %>%
  mutate(model = fct_inorder(model)) %>%
  ggplot(aes(x = model, y = rmse)) + geom_violin(color = "pink")

cv_bwt
```

Based off of the RMSE distribution of the models, I can see that the Model 3 which includes the interaction terms is the best fit for this data. Model 1, my predicted model has a high RMSE value which indicates that it doesn't fit the data appropriately. Model 2 which includes some of the parameters from Model 3 has an RMSE value in the middle which shows that it fits the data better than Model 1 but not as well as Model 3. 

# Problem 2: 
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r}
set.seed(3)

boot_function = function(df) {
  sample_frac(df, size = 0.5, replace = TRUE)
}
```

```{r}
boot_straps_sample = 
  tibble(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_function(weather_df))
  )
```
## Produce estimates for log(Beta 0*Beta1)
```{r}
bootstrap_results = 
  boot_straps_sample %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  unnest(cols = c(results)) %>%
  select(strap_number, term, estimate) %>% 
  pivot_wider(names_from = term, values_from = estimate) %>%
  janitor::clean_names() %>%
  rename(b0 = intercept, b1 = tmin) %>%
  mutate(log_b0b1 = log(b0*b1)) %>%
  select(-b0, -b1)
```

## Produce estimates for r^2 
```{r}
bootstrap_results_rsquared = 
  boot_straps_sample %>%
  mutate(
   models= map(strap_sample, ~lm(tmax~tmin, data = .x)), 
   results = map(models, broom::glance)) %>%
  select(-strap_sample, -models) %>%
  unnest(cols = c(results)) %>%
  select(strap_number, r.squared) %>%
  rename(r2 = r.squared)
```

## Producing Plots 
```{r}
plot_1 = 
  bootstrap_results %>%
  ggplot(aes(x = log_b0b1)) + geom_density(color = "blue") 

plot_1
```

Based on the plot above, we can see that the distribution of log(b0 * b1) is approximately normal which might be due to the fact that we performed a log transformation to log(b0 * b1).We can infer that 95% confidence interval for log(b0*b1) based off the 2.5% and 97.5% quantiles is approximately (1.925, 2.075)

```{r}
plot_2 = 
  bootstrap_results_rsquared %>%
  ggplot(aes(x = r2)) + geom_density(color = "orange")

plot_2
```

Based on the plot above, we can see that the distribution for our r^2 values is slightly left skewed. We can infer that the 95% confidence interval for r^2 based off the 2.5% and 97.5% quantiles is approximately (0.8875, 0.9375)